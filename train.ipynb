{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVoPR1rp9emM",
        "outputId": "540c4ca8-52af-4426-afa0-46fd07763d76"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
            "  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed datasets-2.19.0 dill-0.3.8 huggingface-hub-0.22.2 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ktx9QnbP9uj7",
        "outputId": "07fec154-5908-4e3f-9df9-4694ce5a53f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.19.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.22.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.2\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.29.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NQDnCl2B9UqK"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from transformers import PreTrainedTokenizerFast, CamembertForTokenClassification, AutoModelForTokenClassification,TrainingArguments,DataCollatorForTokenClassification,Trainer\n",
        "import yaml\n",
        "import re\n",
        "from datasets import load_dataset,Dataset, load_metric\n",
        "import evaluate\n",
        "import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import importlib\n",
        "import ast\n",
        "import pandas as pd\n",
        "import preprocess\n",
        "import torch\n",
        "import accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ajl7UOi79UqN",
        "outputId": "7b1d1dca-d243-4612-b423-f0d818b4e828"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'preprocess' from '/content/preprocess.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "importlib.reload(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fH3JSvpQ9UqN"
      },
      "outputs": [],
      "source": [
        "literal2tag=preprocess.literal2tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF1tHUrL9UqO",
        "outputId": "90857646-3b8e-49c6-f26f-295919311141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :   L. et Cher\n",
            "sentence not in right format :   L et Ch\n",
            "sentence not in right format :  L. et Ch.\n",
            "sentence not in right format :  Cher\n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  $$\n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n",
            "sentence not in right format :  \n"
          ]
        }
      ],
      "source": [
        "df=preprocess.get_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CTD5dLaC9UqP"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6IEjN01V9UqP"
      },
      "outputs": [],
      "source": [
        "dataset=load_dataset('csv',data_files='data.csv',num_proc=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Nlj82tkD9UqQ"
      },
      "outputs": [],
      "source": [
        "features=datasets.Features(\n",
        "                {\n",
        "                    \"text\": datasets.Sequence(datasets.Value(\"string\")),\n",
        "                    \"labels\": datasets.Sequence(\n",
        "                        datasets.features.ClassLabel(\n",
        "                            num_classes=len(literal2tag),\n",
        "                            names=literal2tag,\n",
        "                        )\n",
        "                    ),\n",
        "\n",
        "                }\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvbNSSJJ9UqQ",
        "outputId": "22cffe9d-8e9c-49d0-f530-d3489b3d8655"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
              " 'labels': Sequence(feature=ClassLabel(names=['age', 'birth_date', 'civil_status', 'education_level', 'employer', 'firstname', 'link', 'lob', 'maiden_name', 'nationality', 'observation', 'occupation', 'surname', 'surname_household'], id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QVhlomxk9UqR"
      },
      "outputs": [],
      "source": [
        "dataset = dataset['train'].map(lambda example: {\"text\": ast.literal_eval(example[\"text\"]), \"labels\": ast.literal_eval(example[\"labels\"])}, features=features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XsXneTpJ9UqR"
      },
      "outputs": [],
      "source": [
        "dataset=dataset.train_test_split(test_size=0.2,seed=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddQMIlFE9UqS",
        "outputId": "2527a4b0-1b8c-4e55-de40-383a84097c21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'labels'],\n",
              "        num_rows: 18443\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'labels'],\n",
              "        num_rows: 4611\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk1ydjfk9UqT",
        "outputId": "3bdef134-1b26-473b-eecc-c301dbfb54fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'CamembertTokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        }
      ],
      "source": [
        "tokenizer=PreTrainedTokenizerFast.from_pretrained('camembert-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9Pmgk019UqT",
        "outputId": "2a318de1-6c4e-408c-ea29-64fd56edfd2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJB4A7-hOWh5",
        "outputId": "b30fbc3d-61cc-4ce5-d7e3-6e90b0728615"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32005"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "4YpZEXkG9UqT"
      },
      "outputs": [],
      "source": [
        "label_all_tokens = False\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(examples[\"text\"], padding=True, is_split_into_words=True,return_tensors='pt')\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"labels\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
        "            # ignored in the loss function.\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            # We set the label for the first token of each word.\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
        "            # the label_all_tokens flag.\n",
        "            else:\n",
        "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "u2HeqWD89UqU"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets=dataset.map(tokenize_and_align_labels, batched=True,num_proc=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HY-OtU49UqU",
        "outputId": "29283208-f0ef-40f6-aa24-716abec3c23c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model=AutoModelForTokenClassification.from_pretrained('camembert-base', num_labels=14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGLRigBD9UqU",
        "outputId": "ab1dae26-a026-4cc8-ce73-34a6106ef7d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(32006, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "model.resize_token_embeddings(len(tokenizer)+1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7QQS-5xOqtW",
        "outputId": "9467c0ea-a2cf-4d5c-fd61-ebc8a9442517"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CamembertForTokenClassification(\n",
              "  (roberta): CamembertModel(\n",
              "    (embeddings): CamembertEmbeddings(\n",
              "      (word_embeddings): Embedding(32006, 768)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): CamembertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=14, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5NMa23V9UqV",
        "outputId": "0059d664-01c1-40a2-8710-1fa91f0de3d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 18443\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 4611\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_ids_to_tokens(tokenized_datasets['test']['input_ids'][3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mObi0AbZ-mfA",
        "outputId": "0afc169d-d2f0-43f2-8ea1-bee6bceb3ced"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>',\n",
              " '▁Mah',\n",
              " 'é',\n",
              " '▁Pierre',\n",
              " '▁Taille',\n",
              " 'ur',\n",
              " '▁32',\n",
              " '</s>',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PBzNpiqG9UqV"
      },
      "outputs": [],
      "source": [
        "#model(input_ids=tokenized_datasets['train']['input_ids'][0:1],attention_mask=tokenized_datasets['train']['attention_mask'][0:1],token_type_ids=tokenized_datasets['train']['token_type_ids'][0:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "V6uN03bL9UqV"
      },
      "outputs": [],
      "source": [
        "args = TrainingArguments(\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=False,\n",
        "    output_dir='/home/onyxia/work'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "81CNttHf9UqV"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForTokenClassification(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOes0nBE9UqW",
        "outputId": "4dabd2f4-c51b-4dbd-f562-0cf4ce8e2501"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataCollatorForTokenClassification(tokenizer=PreTrainedTokenizerFast(name_or_path='camembert-base', vocab_size=32005, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'pad_token': '[PAD]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
              "\t0: AddedToken(\"<s>NOTUSED\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t2: AddedToken(\"</s>NOTUSED\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t4: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t5: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t6: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t32004: AddedToken(\"<mask>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t32005: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}, padding=True, max_length=None, pad_to_multiple_of=None, label_pad_token_id=-100, return_tensors='pt')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "data_collator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZNbtT-M9UqX",
        "outputId": "b3b95c33-eff4-4424-97f8-378426877643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.4.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-26ba7ae7cb61>:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"seqeval\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/seqeval/seqeval.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "!pip install seqeval\n",
        "metric = load_metric(\"seqeval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1eMYeB749UqY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "label_list=literal2tag\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(F.softmax(torch.Tensor(predictions)), axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggz6mPfO9UqY"
      },
      "source": [
        "\"recall\": metric2.compute(predictions=Value(true_predictions), references=Value(true_labels),average='micro'),\n",
        "        \"f1\": metric3.compute(predictions=Value(true_predictions), references=Value(true_labels),average='micro'),\n",
        "        \"accuracy\": metric4.compute(predictions=Value(true_predictions), references=Value(true_labels)),"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "C3KJPuCq9UqZ"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W2GtvlAG9UqZ",
        "outputId": "112dea3a-79b5-4e26-c34d-9098d9a60bfd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6918' max='6918' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6918/6918 08:04, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.181000</td>\n",
              "      <td>0.126233</td>\n",
              "      <td>0.974905</td>\n",
              "      <td>0.974421</td>\n",
              "      <td>0.974663</td>\n",
              "      <td>0.975071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.080300</td>\n",
              "      <td>0.083668</td>\n",
              "      <td>0.975181</td>\n",
              "      <td>0.974873</td>\n",
              "      <td>0.975027</td>\n",
              "      <td>0.975251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.069800</td>\n",
              "      <td>0.077250</td>\n",
              "      <td>0.975316</td>\n",
              "      <td>0.975008</td>\n",
              "      <td>0.975162</td>\n",
              "      <td>0.975387</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-d4a143bd0101>:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  predictions = np.argmax(F.softmax(torch.Tensor(predictions)), axis=2)\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: surname_household seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: firstname seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: occupation seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: link seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: age seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: surname seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: birth_date seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: nationality seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: civil_status seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: employer seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: lob seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: maiden_name seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: observation seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-29-d4a143bd0101>:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  predictions = np.argmax(F.softmax(torch.Tensor(predictions)), axis=2)\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: surname_household seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: firstname seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: occupation seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: link seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: age seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: surname seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: birth_date seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: nationality seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: civil_status seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: employer seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: lob seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: observation seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: maiden_name seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-29-d4a143bd0101>:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  predictions = np.argmax(F.softmax(torch.Tensor(predictions)), axis=2)\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: surname_household seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: firstname seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: occupation seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: link seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: age seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: surname seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: birth_date seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: nationality seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: civil_status seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: employer seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: lob seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: observation seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: maiden_name seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=6918, training_loss=0.20103254232767795, metrics={'train_runtime': 486.0902, 'train_samples_per_second': 113.825, 'train_steps_per_second': 14.232, 'total_flos': 804059068508004.0, 'train_loss': 0.20103254232767795, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "0C7A63zrLJTX",
        "outputId": "3370c1d7-b518-4d41-c1cd-923fd0e4d496"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='577' max='577' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [577/577 00:08]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-d4a143bd0101>:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  predictions = np.argmax(F.softmax(torch.Tensor(predictions)), axis=2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.07724986225366592,\n",
              " 'eval_precision': 0.9753158844765343,\n",
              " 'eval_recall': 0.9750078946181261,\n",
              " 'eval_f1': 0.9751618652288673,\n",
              " 'eval_accuracy': 0.9753865572735879,\n",
              " 'eval_runtime': 9.5389,\n",
              " 'eval_samples_per_second': 483.387,\n",
              " 'eval_steps_per_second': 60.489,\n",
              " 'epoch': 3.0}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **A few tests**"
      ],
      "metadata": {
        "id": "KHRNDn0HiCfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets['train']['input_ids'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV4wWcI1LzmV",
        "outputId": "c3a1ad2d-3a10-4a02-c637-8cc12be2e878"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5,\n",
              " 84,\n",
              " 5008,\n",
              " 7593,\n",
              " 470,\n",
              " 27312,\n",
              " 918,\n",
              " 8,\n",
              " 401,\n",
              " 3294,\n",
              " 6,\n",
              " 32005,\n",
              " 32005,\n",
              " 32005,\n",
              " 32005,\n",
              " 32005,\n",
              " 32005,\n",
              " 32005,\n",
              " 32005,\n",
              " 32005,\n",
              " 32005,\n",
              " 32005,\n",
              " 32005]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=trainer.predict(tokenized_datasets['test'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "el2EikP7Mbuf",
        "outputId": "fd32a5bf-cedb-4cf9-f9a5-9ebf90bba127"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-d4a143bd0101>:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  predictions = np.argmax(F.softmax(torch.Tensor(predictions)), axis=2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "F.softmax(torch.Tensor(predictions.predictions[3]),dim=-1).argmax(dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmn7KX9lWoR3",
        "outputId": "623e6e2a-9de7-4256-ec9e-5dc0a5144374"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2, 13, 13,  5, 11, 11,  0,  2,  2,  2,  2,  2,  2,  2, 11,  6,  2,  2,\n",
              "         2,  2,  2,  0,  0,  0,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['test']['labels'][:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A8As9eFXR20",
        "outputId": "76e8963e-00f9-42b8-c033-03c58a882a79"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[13, 5, 11, 6, 0],\n",
              " [12, 5, 11, 6, 1, 9],\n",
              " [12, 5, 6, 0],\n",
              " [13, 5, 11, 0],\n",
              " [12, 5, 6, 0, 2],\n",
              " [13, 5, 11, 6, 1, 9],\n",
              " [12, 5, 11, 6, 1, 9],\n",
              " [12, 5, 11, 6, 1, 9],\n",
              " [12, 5, 11, 6, 4, 0],\n",
              " [12, 5, 11, 1, 2, 7]]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets['test']['labels'][3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsMkhpxbbAMu",
        "outputId": "6f2c74a8-91df-49da-e20a-3a0035bc3f73"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-100,\n",
              " 13,\n",
              " -100,\n",
              " 5,\n",
              " 11,\n",
              " -100,\n",
              " 0,\n",
              " -100,\n",
              " -100,\n",
              " -100,\n",
              " -100,\n",
              " -100,\n",
              " -100,\n",
              " -100,\n",
              " -100,\n",
              " -100,\n",
              " -100,\n",
              " -100,\n",
              " -100,\n",
              " -100,\n",
              " -100]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WV08o5xLJ-c",
        "outputId": "4e6b6445-1c84-4472-928c-f821dfe675cb"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32005"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "!pip install seqeval\n",
        "seqeval = evaluate.load('seqeval')\n",
        "predictions = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
        "references = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
        "results = seqeval.compute(predictions=predictions, references=references)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98g17jdcMYYo",
        "outputId": "d08437dc-a2ff-4440-8e2b-b5a8afab4eac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.4.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=18e0d9b46838bc9b95d6c03afe87d41afec5ac69ea2ab11da619bc454bf346a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A14jxdoScrjv",
        "outputId": "ceb94c85-de91-41b5-983f-2b688cc3c31f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MISC': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1},\n",
              " 'PER': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
              " 'overall_precision': 0.5,\n",
              " 'overall_recall': 0.5,\n",
              " 'overall_f1': 0.5,\n",
              " 'overall_accuracy': 0.8}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [['age','surname','link'], ['age','age','link']]\n",
        "references = [['birth_date','link','surname'], ['age','age','link']]"
      ],
      "metadata": {
        "id": "oxMUTCDVffhS"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = seqeval.compute(predictions=predictions, references=references)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuSqMK5tfzDr",
        "outputId": "8e0569e6-b38b-4863-87af-ca1c8594d69a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: birth_date seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: link seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: surname seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: age seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnrPyZyof0wh",
        "outputId": "23ad327d-ff53-4ee7-9611-eed349a2415e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ge': {'precision': 0.5,\n",
              "  'recall': 1.0,\n",
              "  'f1': 0.6666666666666666,\n",
              "  'number': 1},\n",
              " 'ink': {'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2},\n",
              " 'irth_date': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1},\n",
              " 'urname': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1},\n",
              " 'overall_precision': 0.4,\n",
              " 'overall_recall': 0.4,\n",
              " 'overall_f1': 0.4000000000000001,\n",
              " 'overall_accuracy': 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, f1_score\n",
        "\n",
        "def calculate_precision(predictions, true_values):\n",
        "    # Flatten the predictions and true values\n",
        "    flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "    flat_true_values = [item for sublist in true_values for item in sublist]\n",
        "    # Calculate precision\n",
        "    precision = precision_score(flat_true_values, flat_predictions, average='weighted')\n",
        "    return precision\n",
        "\n",
        "def calculate_f1_score(predictions, true_values):\n",
        "    # Flatten the predictions and true values\n",
        "    flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "    flat_true_values = [item for sublist in true_values for item in sublist]\n",
        "    # Calculate F1 score\n",
        "    f1 = f1_score(flat_true_values, flat_predictions, average='weighted')\n",
        "    return f1"
      ],
      "metadata": {
        "id": "Ot7IfTa9f7ph"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_precision(predictions,references)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsaOT3r6gpen",
        "outputId": "07180da2-38b4-4aa1-ae79-f1d08a3a5f32"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38888888888888884"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_f1_score(predictions,references)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbdiDD5lgwBX",
        "outputId": "35ac4471-a5d9-41e6-bc10-45a8166e748f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43333333333333335"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(predictions,true_values):\n",
        "    acc=0\n",
        "    length=0\n",
        "    for i in range (len(predictions)):\n",
        "        length=length+len(predictions[i])\n",
        "        for j in range (len(predictions[i])):\n",
        "            if (predictions[i][j]==true_values[i][j]):\n",
        "                acc=acc+1\n",
        "    return acc/length"
      ],
      "metadata": {
        "id": "4B6icuzNhAs6"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_accuracy(predictions,references)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD0aOBcAhDkQ",
        "outputId": "003c5908-0a34-4e6b-ca66-44e282811148"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "KHRNDn0HiCfJ"
      ],
      "gpuType": "V100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}